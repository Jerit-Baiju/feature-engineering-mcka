{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74769c7a",
   "metadata": {},
   "source": [
    "# Understanding Data Types for Machine Learning\n",
    "\n",
    "In machine learning, understanding and handling different data types is crucial for effective feature engineering, model selection, and evaluation. This notebook explores the main categories of data types with practical examples using a realistic employee dataset, focusing on their impact on ML workflows.\n",
    "\n",
    "## Data Type Classification in ML\n",
    "\n",
    "Data used in machine learning can be broadly classified into two main categories:\n",
    "\n",
    "1. **Quantitative Data** (Numerical): Data that can be measured and expressed numerically. These features are often used directly in ML models or transformed for better performance.\n",
    "   - **Discrete**: Countable values (e.g., number of employees, number of projects)\n",
    "   - **Continuous**: Measurable values that can take any value within a range (e.g., salary, height, temperature)\n",
    "\n",
    "2. **Qualitative Data** (Categorical): Data that represents categories or groups. These features often require encoding before being used in ML algorithms.\n",
    "   - **Nominal**: Categories without inherent order (e.g., gender, department, color)\n",
    "   - **Ordinal**: Categories with a natural order (e.g., education level, performance rating)\n",
    "\n",
    "Let's explore these concepts with a practical example relevant to machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fc2f30",
   "metadata": {},
   "source": [
    "## Creating a Sample Employee Dataset for ML\n",
    "\n",
    "Let's create a realistic employee dataset that demonstrates different data types. This dataset will serve as a foundation for feature engineering and model building in machine learning tasks, such as predicting employee performance or salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee4e61e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Dataset:\n",
      "   employee_id           name   department  years_experience     salary  \\\n",
      "0         1001  Alice Johnson  Engineering                 5   75000.50   \n",
      "1         1002      Bob Smith    Marketing                 8   82000.75   \n",
      "2         1003    Carol Davis  Engineering                 3   68000.00   \n",
      "3         1004   David Wilson        Sales                12   95000.25   \n",
      "4         1005      Eva Brown           HR                 7   71000.80   \n",
      "5         1006   Frank Miller  Engineering                 2   62000.00   \n",
      "6         1007     Grace Chen    Marketing                 6   78000.30   \n",
      "7         1008   Henry Taylor        Sales                15  105000.00   \n",
      "8         1009    Iris Garcia      Finance                 4   73000.60   \n",
      "9         1010  Jack Anderson  Engineering                 9   87000.90   \n",
      "\n",
      "  education_level performance_rating  \n",
      "0        Bachelor               Good  \n",
      "1          Master          Excellent  \n",
      "2        Bachelor            Average  \n",
      "3          Master          Excellent  \n",
      "4        Bachelor               Good  \n",
      "5        Bachelor            Average  \n",
      "6             PhD          Excellent  \n",
      "7          Master          Excellent  \n",
      "8        Bachelor               Good  \n",
      "9          Master               Good  \n",
      "\n",
      "Dataset Shape: (10, 7)\n",
      "Columns: ['employee_id', 'name', 'department', 'years_experience', 'salary', 'education_level', 'performance_rating']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create a realistic employee dataset\n",
    "employee_data = {\n",
    "    'employee_id': [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010],\n",
    "    'name': ['Alice Johnson', 'Bob Smith', 'Carol Davis', 'David Wilson', 'Eva Brown', \n",
    "             'Frank Miller', 'Grace Chen', 'Henry Taylor', 'Iris Garcia', 'Jack Anderson'],\n",
    "    'department': ['Engineering', 'Marketing', 'Engineering', 'Sales', 'HR', \n",
    "                   'Engineering', 'Marketing', 'Sales', 'Finance', 'Engineering'],\n",
    "    'years_experience': [5, 8, 3, 12, 7, 2, 6, 15, 4, 9],\n",
    "    'salary': [75000.50, 82000.75, 68000.00, 95000.25, 71000.80, \n",
    "               62000.00, 78000.30, 105000.00, 73000.60, 87000.90],\n",
    "    'education_level': ['Bachelor', 'Master', 'Bachelor', 'Master', 'Bachelor', \n",
    "                        'Bachelor', 'PhD', 'Master', 'Bachelor', 'Master'],\n",
    "    'performance_rating': ['Good', 'Excellent', 'Average', 'Excellent', 'Good', \n",
    "                          'Average', 'Excellent', 'Excellent', 'Good', 'Good']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(employee_data)\n",
    "\n",
    "# Display the dataset\n",
    "print(\"Employee Dataset:\")\n",
    "print(df)\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8463e0",
   "metadata": {},
   "source": [
    "## Data Type Analysis for ML Feature Engineering\n",
    "\n",
    "Let's examine the data types present in our dataset and understand how pandas interprets them by default. Recognizing these types is essential for preprocessing, encoding, and selecting appropriate ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a745ddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types in our Dataset:\n",
      "employee_id             int64\n",
      "name                   object\n",
      "department             object\n",
      "years_experience        int64\n",
      "salary                float64\n",
      "education_level        object\n",
      "performance_rating     object\n",
      "dtype: object\n",
      "\n",
      "==================================================\n",
      "\n",
      "Descriptive Statistics for Numerical Columns:\n",
      "       employee_id  years_experience         salary\n",
      "count     10.00000         10.000000      10.000000\n",
      "mean    1005.50000          7.100000   79600.410000\n",
      "std        3.02765          4.067486   13031.574396\n",
      "min     1001.00000          2.000000   62000.000000\n",
      "25%     1003.25000          4.250000   71500.750000\n",
      "50%     1005.50000          6.500000   76500.400000\n",
      "75%     1007.75000          8.750000   85750.862500\n",
      "max     1010.00000         15.000000  105000.000000\n"
     ]
    }
   ],
   "source": [
    "# Display data types\n",
    "print(\"Data Types in our Dataset:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nDescriptive Statistics for Numerical Columns:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d209802",
   "metadata": {},
   "source": [
    "### Extracting Columns by Data Type for Feature Engineering\n",
    "\n",
    "In machine learning, it's important to identify which columns are discrete, continuous, or categorical. This helps in selecting appropriate preprocessing techniques and feature engineering strategies for each type. The following cell demonstrates how to extract columns by their data type using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0fb2df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting columns by data type:\n",
      "Discrete (int) columns: ['employee_id', 'years_experience']\n",
      "Continuous (float) columns: ['salary']\n",
      "Categorical (string/object) columns: ['name', 'department', 'education_level', 'performance_rating']\n"
     ]
    }
   ],
   "source": [
    "# Extracting Data Types for Feature Engineering\n",
    "print(\"Extracting columns by data type:\")\n",
    "\n",
    "# Discrete (int) columns\n",
    "discrete_cols = df.select_dtypes(include=['int64', 'int32']).columns.tolist()\n",
    "print(f\"Discrete (int) columns: {discrete_cols}\")\n",
    "\n",
    "# Continuous (float) columns\n",
    "continuous_cols = df.select_dtypes(include=['float64', 'float32']).columns.tolist()\n",
    "print(f\"Continuous (float) columns: {continuous_cols}\")\n",
    "\n",
    "# Categorical (string/object) columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical (string/object) columns: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3515e61",
   "metadata": {},
   "source": [
    "## 1. Quantitative Data (Numerical) in ML\n",
    "\n",
    "Quantitative data represents measurable quantities and is often used directly as features in machine learning models. Proper handling, such as scaling and normalization, can improve model performance.\n",
    "\n",
    "### 1.1 Discrete Quantitative Data\n",
    "\n",
    "Discrete data consists of countable values, typically integers representing counts or whole numbers. In ML, these features may be used as-is or transformed depending on the algorithm.\n",
    "\n",
    "**Examples from our dataset:**\n",
    "- **`employee_id`**: Unique identifier numbers (1001, 1002, 1003, ...)\n",
    "- **`years_experience`**: Number of years worked (2, 3, 4, 5, 6, 7, 8, 9, 12, 15)\n",
    "\n",
    "**ML Considerations:**\n",
    "- Can be used for tree-based models without scaling\n",
    "- May require normalization for linear models\n",
    "- Often result from counting processes\n",
    "- Gaps between values are meaningful and consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5beba16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Years of Experience Statistics:\n",
      "\tRange: 2 to 15 years\n",
      "\tAverage: 7.1 years\n"
     ]
    }
   ],
   "source": [
    "# Analyzing Discrete Data\n",
    "print(\"\\nYears of Experience Statistics:\")\n",
    "print(f\"\\tRange: {df['years_experience'].min()} to {df['years_experience'].max()} years\")\n",
    "print(f\"\\tAverage: {df['years_experience'].mean():.1f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e1e9a4",
   "metadata": {},
   "source": [
    "### 1.2 Continuous Quantitative Data in ML\n",
    "\n",
    "Continuous data can take any value within a given range and is commonly used as input features for ML models. Proper scaling and transformation are often necessary for optimal model performance.\n",
    "\n",
    "**Examples from our dataset:**\n",
    "- **`salary`**: Employee salaries (62000.00, 68000.00, 71000.80, 73000.60, ...)\n",
    "\n",
    "**ML Considerations:**\n",
    "- Requires scaling (e.g., StandardScaler, MinMaxScaler) for many algorithms\n",
    "- Can be used for regression and classification tasks\n",
    "- Theoretically infinite number of possible values between any two points\n",
    "- Can be meaningfully divided into smaller units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd972b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Data Analysis:\n",
      "\n",
      "Salary Statistics:\n",
      "\tMinimum Salary: $62,000.00\n",
      "\tMaximum Salary: $105,000.00\n",
      "\tAverage Salary: $79,600.41\n",
      "\tMedian Salary: $76,500.40\n",
      "\tSalary Range: $43,000.00\n"
     ]
    }
   ],
   "source": [
    "# Analyzing Continuous Data\n",
    "print(\"Continuous Data Analysis:\")\n",
    "print(\"\\nSalary Statistics:\")\n",
    "print(f\"\\tMinimum Salary: ${df['salary'].min():,.2f}\")\n",
    "print(f\"\\tMaximum Salary: ${df['salary'].max():,.2f}\")\n",
    "print(f\"\\tAverage Salary: ${df['salary'].mean():,.2f}\")\n",
    "print(f\"\\tMedian Salary: ${df['salary'].median():,.2f}\")\n",
    "print(f\"\\tSalary Range: ${df['salary'].max() - df['salary'].min():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b604de0",
   "metadata": {},
   "source": [
    "## 2. Qualitative Data (Categorical) in ML\n",
    "\n",
    "Qualitative data represents categories or groups and must be encoded before being used in most machine learning models. Proper encoding (e.g., one-hot, label encoding) is essential for effective feature engineering.\n",
    "\n",
    "### 2.1 Nominal Categorical Data in ML\n",
    "\n",
    "Nominal data represents categories without any inherent order or ranking. These features are typically encoded using one-hot encoding for ML models.\n",
    "\n",
    "**Examples from our dataset:**\n",
    "- **`name`**: Employee names (Alice Johnson, Bob Smith, Carol Davis, ...)\n",
    "- **`department`**: Department names (Engineering, Marketing, Sales, HR, Finance)\n",
    "\n",
    "**ML Considerations:**\n",
    "- One-hot encoding is commonly used\n",
    "- Categories have no natural order\n",
    "- Only equality comparisons make sense (equal or not equal)\n",
    "- Mode is the only meaningful measure of central tendency\n",
    "- Can be represented by numbers, but mathematical operations are meaningless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe6d3ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal Categorical Data Analysis:\n",
      "\n",
      "Department Distribution:\n",
      "department\n",
      "Engineering    4\n",
      "Marketing      2\n",
      "Sales          2\n",
      "HR             1\n",
      "Finance        1\n",
      "Name: count, dtype: int64\n",
      "Number of unique departments: 5\n"
     ]
    }
   ],
   "source": [
    "# Analyzing Nominal Categorical Data\n",
    "print(\"Nominal Categorical Data Analysis:\")\n",
    "\n",
    "print(\"\\nDepartment Distribution:\")\n",
    "dept_counts = df['department'].value_counts()\n",
    "print(dept_counts)\n",
    "print(f\"Number of unique departments: {df['department'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f99022",
   "metadata": {},
   "source": [
    "### 2.2 Ordinal Categorical Data in ML\n",
    "\n",
    "Ordinal data represents categories with a natural order or ranking. In ML, these features can be encoded using label encoding or custom mappings to preserve order.\n",
    "\n",
    "**Examples from our dataset:**\n",
    "- **`education_level`**: Education levels (Bachelor < Master < PhD)\n",
    "- **`performance_rating`**: Performance ratings (Average < Good < Excellent)\n",
    "\n",
    "**ML Considerations:**\n",
    "- Label encoding or custom ordinal mapping is preferred\n",
    "- Categories have a natural, meaningful order\n",
    "- Differences between categories may not be equal or measurable\n",
    "- Median and mode are meaningful measures of central tendency\n",
    "- Can use comparison operators (<, >, ≤, ≥) in addition to equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6afd618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Categorical Data Analysis:\n",
      "\n",
      "Education Level Distribution:\n",
      "education_level\n",
      "Bachelor    5\n",
      "Master      4\n",
      "PhD         1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performance Rating Distribution:\n",
      "performance_rating\n",
      "Good         4\n",
      "Excellent    4\n",
      "Average      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Unique Education Levels: 3\n",
      "Unique Performance Ratings: 3\n"
     ]
    }
   ],
   "source": [
    "# Concise Ordinal Categorical Data Analysis\n",
    "print(\"Ordinal Categorical Data Analysis:\")\n",
    "\n",
    "# Show value counts for education_level and performance_rating\n",
    "print(\"\\nEducation Level Distribution:\")\n",
    "print(df['education_level'].value_counts())\n",
    "\n",
    "print(\"\\nPerformance Rating Distribution:\")\n",
    "print(df['performance_rating'].value_counts())\n",
    "\n",
    "# Show number of unique categories\n",
    "print(f\"\\nUnique Education Levels: {df['education_level'].nunique()}\")\n",
    "print(f\"Unique Performance Ratings: {df['performance_rating'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5db7d6",
   "metadata": {},
   "source": [
    "## Summary: Data Types for Machine Learning\n",
    "\n",
    "Let's summarize the data types present in our employee dataset and their relevance for ML feature engineering:\n",
    "\n",
    "| Column | Data Type Category | Sub-category | Pandas Type | ML Considerations |\n",
    "|--------|-------------------|--------------|-------------|------------------|\n",
    "| `employee_id` | Quantitative | Discrete | int64 | Unique identifier, usually excluded from features |\n",
    "| `name` | Qualitative | Nominal | object | Identifier, not used as a feature |\n",
    "| `department` | Qualitative | Nominal | object | One-hot encoding for ML models |\n",
    "| `years_experience` | Quantitative | Discrete | int64 | Used directly or normalized |\n",
    "| `salary` | Quantitative | Continuous | float64 | Scaling required for many models |\n",
    "| `education_level` | Qualitative | Ordinal | object | Ordinal encoding preserves order |\n",
    "| `performance_rating` | Qualitative | Ordinal | object | Ordinal encoding preserves ranking |\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
